# Introduction
As AI models evolve, detecting AI-generated text becomes increasingly challenging. Advanced models, especially when multiple LLMs collaborate in generating content, can effectively evade detection systems, mimicking human writing with high fluency. Traditional methods often fail to distinguish between AI and human-authored text. To address these challenges, we propose an enhanced detection framework that excels even against sophisticated evasion attempts. First, we leverage open source models (Gemma2-9b, Qwen2-7b, GPT-2-Large) to calculate token loss and perplexity, strengthening detection accuracy. Second, we incorporate semantic, part-of-speech (PoS), and bigram features to capture subtle human-like nuances. Our method demonstrates superior performance in identifying AI-generated content, even when crafted using Multi-LLM techniques for evasion. This work offers new insights into robust content analysis and improves the detection of AI-generated text.
<p align="center">
  <img src="https://github.com/user-attachments/assets/b88a562e-5615-4a86-a600-305204a80c46" alt="The text generation process of multi-LLM system">
  <br>
  The text generation process of multi-LLM system
</p>

# DetevaGPT
To address the challenges of sentence-level AI-generated text detection, we integrate semantic features, writing style features, and perplexity as foundational features for detecting AI-generated content. At the same time, we incorporate training data generated by multiple LLMs into the training set. On one hand, this approach allows us to validate the effectiveness of our proposed method in detecting content generated by newer, larger models. On the other hand, it enables us to verify that text generated by multiple LLMs is closer to human writing and thus more difficult to detect, which contributes to train a more robust detection model. We refer to our method as DetevaGPT.Our DetevaGPT model is composed of three parts: Feature extraction, feature encoding, and sequence labeling.
<p align="center">
  <img src="https://github.com/user-attachments/assets/558b39a9-858d-48b9-9fda-12adaea8d35c" alt="Model structure of DetevaGPT">
  <br>
  Model structure of DetevaGPT
</p>

# Performance
All the values listed in our table are F1 scores scores to consider the overall performance. 

# Binary classification test result sbasedon GPT-4o and GPT-4o-Multi and GPT-3.5 and GPT-3.5-Multi data
|     Method      | GPT-4o | GPT-4o-Multi |  Method         | GPT-3.5| GPT-3.5-Multi |
| --------------- | -------| -------------| --------------- | -------| --------------|
| Fast-Detect-gpt | 59.2   | 53.0         | Fast-Detect-gpt | 56.0   | 42.6          |
| SeqXGPT         | 96.8   | 90.7         |  SeqXGPT        | 95.2   | 82.0          |
| DetevaGPT       | 99.8   | 99.75        | DetevaGPT       | 99.5   | 99.2          |

# Performance Comparison Across Datasets for Different Methods
| Method     | GPT-2 | GPT-3.5 | GPT-4o | GPT-3.5-Multi | GPT-4o-Multi | Qwen2 | LLaMa | Human |
| -----------| --------------- | -------| --------------| -------------| ------| ------| ------|
| Seq-RoBERTa| 88.8  | 91.0    | 97.3   | 39.2          | 82.2         | 77.9  | 80.6  | 92.2  |
| SeqXGPT    | 90.1  | 81.1    | 76.9   | 55.9          | 61.4         | 75.5  | 61.8  | 96.4  |
| DetevaGPT  | 93.2  | 88.1    | 98.8   | 85.9          | 93.4         | 95.6  | 92.1  | 97.3  |


# Training Loss vs Epochs

![image](https://github.com/user-attachments/assets/4432ed53-158d-4430-9a7c-0ba243278d2d)

# UMAP comparison of clustering effects of SeqXGPT and DetevaGPT Table
![image](https://github.com/user-attachments/assets/7f39cc66-dda1-4d58-b496-2b5329aa1199)  ![image](https://github.com/user-attachments/assets/dd556991-2772-43f8-a358-ae4b154999fb)

# Conclusion
We proposed a novel AI-generated text detection model named DetevaGPT, which integrates semantic features, part-of-speech (PoS) features, and bigram features, combined with transformer and CNN architectures to enhance sequence labeling capability and detection performance. Compared to baseline detection methods such as SeqXGPT and Fast-DetectGPT, DetevaGPT demonstrates superior performance, particularly in handling complex texts generated by multiple LLMs. Experimental results show that DetevaGPT can capture richer feature information when detecting multi-LLM-generated texts, improving accuracy in distinguishing AI-generated content from human-written text.We also observed that texts generated by multiple LLMs exhibit a strong evasion effect on other models. These multi-LLM-generated texts are closer to human writing styles, making them harder to detect using traditional methods, and they demonstrate greater fluency and semantic coherence. This evasion effect highlights the limitations of conventional perplexity-based or single-feature detection models when facing more advanced generation models.
By integrating multiple features, DetevaGPT overcomes these limitations, offering more stable performance when dealing with complex text generation. It shows enhanced robustness, particularly in detecting texts generated by multiple LLMs. the ablation experiments further validated the crucial role of writing style features, such as PoS and bigram features, in improving detection performance. Future research includes optimizing both evasion and detection on multi-LLM-generated texts for adversarial training, especially as AI-generated content becomes increasingly more evasive. DetevaGPT provides a solid foundation and direction for addressing this challenge.

# Limitations
Our work on DetevaGPT addresses challenges in detecting AI-generated text, particularly evasion by advanced models. However, several limitations remain. Due to computational constraints, we tested only a subset of models and datasets, leaving some emerging models unexplored.While our framework integrates perplexity, writing style, and semantic features, it relies on labeled datasets, limiting generalization to low-resource domains. The multi-LLM setup involved only two models at a time, which may not fully reflect real-world collaborative AI-generated texts or human-AI co-writing scenarios.Though DetevaGPT performed well, evolving AI models present ongoing challenges. Future work will focus on adaptive training, adversarial techniques, and expanding datasets to further improve detection and robustness.



